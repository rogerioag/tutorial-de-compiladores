{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/rogerioag/tutorial-de-compiladores/blob/master/01_compiladores_analise_lexica_tpplex.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JVjF53sATa07"
   },
   "source": [
    "# Análise Léxica\n",
    "\n",
    "## Preparação do Ambiente\n",
    "\n",
    "*   Instalação do [PLY](https://www.dabeaz.com/ply/ply.html)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "id": "tcwj8f6MSt_u",
    "outputId": "13bd088d-a65a-4c7b-88c6-2059c2477def"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ply in /home/rag/anaconda3/lib/python3.7/site-packages (3.11)\n"
     ]
    }
   ],
   "source": [
    "!pip install ply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SBuIbkFfUppX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "EGxUtELATG9J"
   },
   "outputs": [],
   "source": [
    "from sys import argv, exit\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "     level = logging.DEBUG,\n",
    "     filename = \"log.txt\",\n",
    "     filemode = \"w\",\n",
    "     format = \"%(filename)10s:%(lineno)4d:%(message)s\"\n",
    ")\n",
    "log = logging.getLogger()\n",
    "\n",
    "import ply.lex as lex\n",
    "from ply.lex import TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "8V2XZckUT6vh"
   },
   "outputs": [],
   "source": [
    "tokens = [\n",
    "    \"ID\",  # identificador\n",
    "    # numerais\n",
    "    \"NUM_NOTACAO_CIENTIFICA\",  # ponto flutuante em notaçao científica\n",
    "    \"NUM_PONTO_FLUTUANTE\",  # ponto flutuate\n",
    "    \"NUM_INTEIRO\",  # inteiro\n",
    "    # operadores binarios\n",
    "    \"ADICAO\",  # +\n",
    "    \"SUBTRACAO\",  # -\n",
    "    \"MULTIPLICACAO\",  # *\n",
    "    \"DIVISAO\",  # /\n",
    "    \"E_LOGICO\",  # &&\n",
    "    \"OU_LOGICO\",  # ||\n",
    "    \"DIFERENCA\",  # <>\n",
    "    \"MENOR_IGUAL\",  # <=\n",
    "    \"MAIOR_IGUAL\",  # >=\n",
    "    \"MENOR\",  # <\n",
    "    \"MAIOR\",  # >\n",
    "    \"IGUALDADE\",  # =\n",
    "    # operadores unarios\n",
    "    \"NEGACAO\",  # !\n",
    "    # simbolos\n",
    "    \"ABRE_PAR\",  # (\n",
    "    \"FECHA_PAR\",  # )\n",
    "    \"ABRE_COL\",  # [\n",
    "    \"FECHA_COL\",  # ]\n",
    "    \"VIRGULA\",  # ,\n",
    "    \"DOIS_PONTOS\",  # :\n",
    "    \"ATRIBUICAO\",  # :=\n",
    "    # 'COMENTARIO', # {***}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "fZ5adkC1T_dg"
   },
   "outputs": [],
   "source": [
    "reserved_words = {\n",
    "    \"se\": \"SE\",\n",
    "    \"então\": \"ENTAO\",\n",
    "    \"senão\": \"SENAO\",\n",
    "    \"fim\": \"FIM\",\n",
    "    \"repita\": \"REPITA\",\n",
    "    \"flutuante\": \"FLUTUANTE\",\n",
    "    \"retorna\": \"RETORNA\",\n",
    "    \"até\": \"ATE\",\n",
    "    \"leia\": \"LEIA\",\n",
    "    \"escreva\": \"ESCREVA\",\n",
    "    \"inteiro\": \"INTEIRO\",\n",
    "}\n",
    "\n",
    "tokens = tokens + list(reserved_words.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "px_JLT-mUEqx"
   },
   "outputs": [],
   "source": [
    "digito = r\"([0-9])\"\n",
    "letra = r\"([a-zA-ZáÁãÃàÀéÉíÍóÓõÕ])\"\n",
    "sinal = r\"([\\-\\+]?)\"\n",
    "\n",
    "\"\"\" \n",
    "    id deve começar com uma letra\n",
    "\"\"\"\n",
    "id = (\n",
    "    r\"(\" + letra + r\"(\" + digito + r\"+|_|\" + letra + r\")*)\"\n",
    ")  # o mesmo que '((letra)(letra|_|([0-9]))*)'\n",
    "\n",
    "inteiro = r\"(\" + sinal + digito + r\"+)\"\n",
    "\n",
    "flutuante = (\n",
    "    # r\"(\" + digito + r\"+\\.\" + digito + r\"+?)\"\n",
    "    # (([-\\+]?)([0-9]+)\\.([0-9]+))'\n",
    "    r'\\d+[eE][-+]?\\d+|(\\.\\d+|\\d+\\.\\d*)([eE][-+]?\\d+)?'\n",
    "    # r'[-+]?[0-9]+(\\.([0-9]+)?)'\n",
    "    #r'[+-]?(\\d+(\\.\\d*)?|\\.\\d+)([eE][+-]?\\d+)?'\n",
    "    #r\"(([-\\+]?)([0-9]+)\\.([0-9]+))\"\n",
    "    )\n",
    "\n",
    "notacao_cientifica = (\n",
    "    r\"(\" + sinal + r\"([1-9])\\.\" + digito + r\"+[eE]\" + sinal + digito + r\"+)\"\n",
    ")  # o mesmo que '(([-\\+]?)([1-9])\\.([0-9])+[eE]([-\\+]?)([0-9]+))'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "HuIxrFzjUIY8"
   },
   "outputs": [],
   "source": [
    " \n",
    "# Expressões Regulaes para tokens simples.\n",
    "# Símbolos.\n",
    "t_ADICAO    = r'\\+'\n",
    "t_SUBTRACAO  = r'-'\n",
    "t_MULTIPLICACAO   = r'\\*'\n",
    "t_DIVISAO = r'/'\n",
    "t_ABRE_PAR  = r'\\('\n",
    "t_FECHA_PAR  = r'\\)'\n",
    "t_ABRE_COL = r'\\['\n",
    "t_FECHA_COL = r'\\]'\n",
    "t_VIRGULA = r','\n",
    "t_ATRIBUICAO = r':='\n",
    "t_DOIS_PONTOS = r':'\n",
    "\n",
    "# Operadores Lógicos.\n",
    "t_E_LOGICO = r'&&'\n",
    "t_OU_LOGICO = r'\\|\\|'\n",
    "t_NEGACAO = r'!'\n",
    "\n",
    "# Operadores Relacionais.\n",
    "t_DIFERENCA = r'<>'\n",
    "t_MENOR_IGUAL = r'<='\n",
    "t_MAIOR_IGUAL = r'>='\n",
    "t_MENOR = r'<'\n",
    "t_MAIOR = r'>'\n",
    "t_IGUALDADE = r'='"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "y-gnMlvxUL00"
   },
   "outputs": [],
   "source": [
    "@TOKEN(id)\n",
    "def t_ID(token):\n",
    "    token.type = reserved_words.get(\n",
    "        token.value, \"ID\"\n",
    "    )  # não é necessário fazer regras/regex para cada palavra reservada\n",
    "    # se o token não for uma palavra reservada automaticamente é um id\n",
    "    # As palavras reservadas têm precedências sobre os ids\n",
    "\n",
    "    return token\n",
    "\n",
    "@TOKEN(notacao_cientifica)\n",
    "def t_NUM_NOTACAO_CIENTIFICA(token):\n",
    "    return token\n",
    "\n",
    "@TOKEN(flutuante)\n",
    "def t_NUM_PONTO_FLUTUANTE(token):\n",
    "    return token\n",
    "\n",
    "@TOKEN(inteiro)\n",
    "def t_NUM_INTEIRO(token):\n",
    "    return token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "UPVsN3naUO0W"
   },
   "outputs": [],
   "source": [
    "t_ignore = \" \\t\"\n",
    "\n",
    "# t_COMENTARIO = r'(\\{((.|\\n)*?)\\})'\n",
    "# para poder contar as quebras de linha dentro dos comentarios\n",
    "def t_COMENTARIO(token):\n",
    "    r\"(\\{((.|\\n)*?)\\})\"\n",
    "    token.lexer.lineno += token.value.count(\"\\n\")\n",
    "    # return token\n",
    "\n",
    "def t_newline(token):\n",
    "    r\"\\n+\"\n",
    "    token.lexer.lineno += len(token.value)\n",
    "\n",
    "def define_column(input, lexpos):\n",
    "    begin_line = input.rfind(\"\\n\", 0, lexpos) + 1\n",
    "    return (lexpos - begin_line) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "xC49Ezx-USJ7"
   },
   "outputs": [],
   "source": [
    "def t_error(token):\n",
    "\n",
    "    # file = token.lexer.filename\n",
    "    line = token.lineno\n",
    "    # column = define_column(token.lexer.backup_data, token.lexpos)\n",
    "    message = \"Caracter ilegal '%s'\" % token.value[0]\n",
    "\n",
    "    # print(f\"[{file}]:[{line},{column}]: {message}.\") \n",
    "    print(message)\n",
    "\n",
    "    token.lexer.skip(1)\n",
    "\n",
    "    # token.lexer.has_error = Trueb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "q9_fzwX8UWnf"
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    # argv[1] = 'teste.tpp'\n",
    "    aux = argv[1].split('.')\n",
    "    if aux[-1] != 'tpp':\n",
    "      raise IOError(\"Not a .tpp file!\")\n",
    "    data = open(argv[1])\n",
    "\n",
    "    source_file = data.read()\n",
    "    lexer.input(source_file)\n",
    "\n",
    "    # Tokenize\n",
    "    while True:\n",
    "      tok = lexer.token()\n",
    "      if not tok: \n",
    "        break      # No more input\n",
    "      print(tok)\n",
    "      # print(tok.type)\n",
    "      #print(tok.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "w7i4m7zoUcpc",
    "outputId": "30a5a73a-6b50-4b1c-a410-440ab999c033"
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Not a .tpp file!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m01-compiladores-analise-lexica-tpplex.ipynb\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m01-compiladores-analise-lexica-tpplex.ipynb\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maux\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'tpp'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Not a .tpp file!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Not a .tpp file!"
     ]
    }
   ],
   "source": [
    "# Build the lexer.\n",
    "__file__ = \"01-compiladores-analise-lexica-tpplex.ipynb\"\n",
    "lexer = lex.lex(optimize=True,debug=True,debuglog=log)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "TO_H9ZMxoG3M",
    "outputId": "040e1d0f-0dc6-4fa7-9745-be24b37807d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing teste.tpp\n"
     ]
    }
   ],
   "source": [
    "%%writefile teste.tpp\n",
    "\n",
    "inteiro: a[10]\n",
    "flutuante: b\n",
    "\n",
    "inteiro func1(inteiro:x, flutuante:y)\n",
    "  inteiro: res\n",
    "  se (x > y) então\n",
    "    res := x + y\n",
    "  senão\n",
    "    res := x * y\n",
    "  fim\n",
    "  retorna(res)\n",
    "fim\n",
    "\n",
    "func2(inteiro:z, flutuante:w)\n",
    "  a := z\n",
    "  b := w\n",
    "fim\n",
    "\n",
    "inteiro principal()\n",
    "  inteiro: x,y\n",
    "  flutuante: w\n",
    "  a := 10 + 2\n",
    "  leia(x)\n",
    "  leia(w)\n",
    "  w := .6 + 1.\n",
    "  func2(1, 2.5)\n",
    "  b := func1(x,w)\n",
    "  escreva(b)\n",
    "  retorna(0)\n",
    "fim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "y9UN81N7XBz_",
    "outputId": "4c80fe5c-2ed1-407d-eb63-078cdf42b3fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python: can't open file 'tpplex.py': [Errno 2] No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!python tpplex.py teste.tpp"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP5SBr0W/H6P8YM7xM7MHgj",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "01-compiladores-analise-lexica-tpplex.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
