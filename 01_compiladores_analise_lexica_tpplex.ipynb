{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01-compiladores-analise-lexica-tpplex.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP5SBr0W/H6P8YM7xM7MHgj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rogerioag/tutorial-de-compiladores/blob/master/01_compiladores_analise_lexica_tpplex.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVjF53sATa07"
      },
      "source": [
        "# Análise Léxica\n",
        "\n",
        "## Preparação do Ambiente\n",
        "\n",
        "*   Instalação do [PLY](https://www.dabeaz.com/ply/ply.html)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcwj8f6MSt_u",
        "outputId": "13bd088d-a65a-4c7b-88c6-2059c2477def",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "!pip install ply"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting ply\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/58/35da89ee790598a0700ea49b2a66594140f44dec458c07e8e3d4979137fc/ply-3.11-py2.py3-none-any.whl (49kB)\n",
            "\r\u001b[K     |██████▋                         | 10kB 18.7MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 20kB 2.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 30kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 40kB 3.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 2.0MB/s \n",
            "\u001b[?25hInstalling collected packages: ply\n",
            "Successfully installed ply-3.11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBuIbkFfUppX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGxUtELATG9J"
      },
      "source": [
        "from sys import argv, exit\n",
        "\n",
        "import logging\n",
        "logging.basicConfig(\n",
        "     level = logging.DEBUG,\n",
        "     filename = \"log.txt\",\n",
        "     filemode = \"w\",\n",
        "     format = \"%(filename)10s:%(lineno)4d:%(message)s\"\n",
        ")\n",
        "log = logging.getLogger()\n",
        "\n",
        "import ply.lex as lex\n",
        "from ply.lex import TOKEN"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8V2XZckUT6vh"
      },
      "source": [
        "tokens = [\n",
        "    \"ID\",  # identificador\n",
        "    # numerais\n",
        "    \"NUM_NOTACAO_CIENTIFICA\",  # ponto flutuante em notaçao científica\n",
        "    \"NUM_PONTO_FLUTUANTE\",  # ponto flutuate\n",
        "    \"NUM_INTEIRO\",  # inteiro\n",
        "    # operadores binarios\n",
        "    \"ADICAO\",  # +\n",
        "    \"SUBTRACAO\",  # -\n",
        "    \"MULTIPLICACAO\",  # *\n",
        "    \"DIVISAO\",  # /\n",
        "    \"E_LOGICO\",  # &&\n",
        "    \"OU_LOGICO\",  # ||\n",
        "    \"DIFERENCA\",  # <>\n",
        "    \"MENOR_IGUAL\",  # <=\n",
        "    \"MAIOR_IGUAL\",  # >=\n",
        "    \"MENOR\",  # <\n",
        "    \"MAIOR\",  # >\n",
        "    \"IGUALDADE\",  # =\n",
        "    # operadores unarios\n",
        "    \"NEGACAO\",  # !\n",
        "    # simbolos\n",
        "    \"ABRE_PAR\",  # (\n",
        "    \"FECHA_PAR\",  # )\n",
        "    \"ABRE_COL\",  # [\n",
        "    \"FECHA_COL\",  # ]\n",
        "    \"VIRGULA\",  # ,\n",
        "    \"DOIS_PONTOS\",  # :\n",
        "    \"ATRIBUICAO\",  # :=\n",
        "    # 'COMENTARIO', # {***}\n",
        "]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZ5adkC1T_dg"
      },
      "source": [
        "reserved_words = {\n",
        "    \"se\": \"SE\",\n",
        "    \"então\": \"ENTAO\",\n",
        "    \"senão\": \"SENAO\",\n",
        "    \"fim\": \"FIM\",\n",
        "    \"repita\": \"REPITA\",\n",
        "    \"flutuante\": \"FLUTUANTE\",\n",
        "    \"retorna\": \"RETORNA\",\n",
        "    \"até\": \"ATE\",\n",
        "    \"leia\": \"LEIA\",\n",
        "    \"escreva\": \"ESCREVA\",\n",
        "    \"inteiro\": \"INTEIRO\",\n",
        "}\n",
        "\n",
        "tokens = tokens + list(reserved_words.values())"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "px_JLT-mUEqx"
      },
      "source": [
        "digito = r\"([0-9])\"\n",
        "letra = r\"([a-zA-ZáÁãÃàÀéÉíÍóÓõÕ])\"\n",
        "sinal = r\"([\\-\\+]?)\"\n",
        "\n",
        "\"\"\" \n",
        "    id deve começar com uma letra\n",
        "\"\"\"\n",
        "id = (\n",
        "    r\"(\" + letra + r\"(\" + digito + r\"+|_|\" + letra + r\")*)\"\n",
        ")  # o mesmo que '((letra)(letra|_|([0-9]))*)'\n",
        "\n",
        "inteiro = r\"(\" + sinal + digito + r\"+)\"\n",
        "\n",
        "flutuante = (\n",
        "    # r\"(\" + digito + r\"+\\.\" + digito + r\"+?)\"\n",
        "    # (([-\\+]?)([0-9]+)\\.([0-9]+))'\n",
        "    r'\\d+[eE][-+]?\\d+|(\\.\\d+|\\d+\\.\\d*)([eE][-+]?\\d+)?'\n",
        "    # r'[-+]?[0-9]+(\\.([0-9]+)?)'\n",
        "    #r'[+-]?(\\d+(\\.\\d*)?|\\.\\d+)([eE][+-]?\\d+)?'\n",
        "    #r\"(([-\\+]?)([0-9]+)\\.([0-9]+))\"\n",
        "    )\n",
        "\n",
        "notacao_cientifica = (\n",
        "    r\"(\" + sinal + r\"([1-9])\\.\" + digito + r\"+[eE]\" + sinal + digito + r\"+)\"\n",
        ")  # o mesmo que '(([-\\+]?)([1-9])\\.([0-9])+[eE]([-\\+]?)([0-9]+))'"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HuIxrFzjUIY8"
      },
      "source": [
        " \n",
        "# Expressões Regulaes para tokens simples.\n",
        "# Símbolos.\n",
        "t_ADICAO    = r'\\+'\n",
        "t_SUBTRACAO  = r'-'\n",
        "t_MULTIPLICACAO   = r'\\*'\n",
        "t_DIVISAO = r'/'\n",
        "t_ABRE_PAR  = r'\\('\n",
        "t_FECHA_PAR  = r'\\)'\n",
        "t_ABRE_COL = r'\\['\n",
        "t_FECHA_COL = r'\\]'\n",
        "t_VIRGULA = r','\n",
        "t_ATRIBUICAO = r':='\n",
        "t_DOIS_PONTOS = r':'\n",
        "\n",
        "# Operadores Lógicos.\n",
        "t_E_LOGICO = r'&&'\n",
        "t_OU_LOGICO = r'\\|\\|'\n",
        "t_NEGACAO = r'!'\n",
        "\n",
        "# Operadores Relacionais.\n",
        "t_DIFERENCA = r'<>'\n",
        "t_MENOR_IGUAL = r'<='\n",
        "t_MAIOR_IGUAL = r'>='\n",
        "t_MENOR = r'<'\n",
        "t_MAIOR = r'>'\n",
        "t_IGUALDADE = r'='"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-gnMlvxUL00"
      },
      "source": [
        "@TOKEN(id)\n",
        "def t_ID(token):\n",
        "    token.type = reserved_words.get(\n",
        "        token.value, \"ID\"\n",
        "    )  # não é necessário fazer regras/regex para cada palavra reservada\n",
        "    # se o token não for uma palavra reservada automaticamente é um id\n",
        "    # As palavras reservadas têm precedências sobre os ids\n",
        "\n",
        "    return token\n",
        "\n",
        "@TOKEN(notacao_cientifica)\n",
        "def t_NUM_NOTACAO_CIENTIFICA(token):\n",
        "    return token\n",
        "\n",
        "@TOKEN(flutuante)\n",
        "def t_NUM_PONTO_FLUTUANTE(token):\n",
        "    return token\n",
        "\n",
        "@TOKEN(inteiro)\n",
        "def t_NUM_INTEIRO(token):\n",
        "    return token"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPVsN3naUO0W"
      },
      "source": [
        "t_ignore = \" \\t\"\n",
        "\n",
        "# t_COMENTARIO = r'(\\{((.|\\n)*?)\\})'\n",
        "# para poder contar as quebras de linha dentro dos comentarios\n",
        "def t_COMENTARIO(token):\n",
        "    r\"(\\{((.|\\n)*?)\\})\"\n",
        "    token.lexer.lineno += token.value.count(\"\\n\")\n",
        "    # return token\n",
        "\n",
        "def t_newline(token):\n",
        "    r\"\\n+\"\n",
        "    token.lexer.lineno += len(token.value)\n",
        "\n",
        "def define_column(input, lexpos):\n",
        "    begin_line = input.rfind(\"\\n\", 0, lexpos) + 1\n",
        "    return (lexpos - begin_line) + 1"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xC49Ezx-USJ7"
      },
      "source": [
        "def t_error(token):\n",
        "\n",
        "    # file = token.lexer.filename\n",
        "    line = token.lineno\n",
        "    # column = define_column(token.lexer.backup_data, token.lexpos)\n",
        "    message = \"Caracter ilegal '%s'\" % token.value[0]\n",
        "\n",
        "    # print(f\"[{file}]:[{line},{column}]: {message}.\") \n",
        "    print(message)\n",
        "\n",
        "    token.lexer.skip(1)\n",
        "\n",
        "    # token.lexer.has_error = Trueb"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9_fzwX8UWnf"
      },
      "source": [
        "def main():\n",
        "    # argv[1] = 'teste.tpp'\n",
        "    aux = argv[1].split('.')\n",
        "    if aux[-1] != 'tpp':\n",
        "      raise IOError(\"Not a .tpp file!\")\n",
        "    data = open(argv[1])\n",
        "\n",
        "    source_file = data.read()\n",
        "    lexer.input(source_file)\n",
        "\n",
        "    # Tokenize\n",
        "    while True:\n",
        "      tok = lexer.token()\n",
        "      if not tok: \n",
        "        break      # No more input\n",
        "      print(tok)\n",
        "      # print(tok.type)\n",
        "      #print(tok.value)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7i4m7zoUcpc",
        "outputId": "30a5a73a-6b50-4b1c-a410-440ab999c033",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Build the lexer.\n",
        "__file__ = \"01-compiladores-analise-lexica-tpplex.ipynb\"\n",
        "lexer = lex.lex(optimize=True,debug=True,debuglog=log)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LexToken(INTEIRO,'inteiro',2,1)\n",
            "LexToken(DOIS_PONTOS,':',2,8)\n",
            "LexToken(ID,'a',2,10)\n",
            "LexToken(ABRE_COL,'[',2,11)\n",
            "LexToken(NUM_INTEIRO,'10',2,12)\n",
            "LexToken(FECHA_COL,']',2,14)\n",
            "LexToken(FLUTUANTE,'flutuante',3,16)\n",
            "LexToken(DOIS_PONTOS,':',3,25)\n",
            "LexToken(ID,'b',3,27)\n",
            "LexToken(INTEIRO,'inteiro',5,30)\n",
            "LexToken(ID,'func1',5,38)\n",
            "LexToken(ABRE_PAR,'(',5,43)\n",
            "LexToken(INTEIRO,'inteiro',5,44)\n",
            "LexToken(DOIS_PONTOS,':',5,51)\n",
            "LexToken(ID,'x',5,52)\n",
            "LexToken(VIRGULA,',',5,53)\n",
            "LexToken(FLUTUANTE,'flutuante',5,55)\n",
            "LexToken(DOIS_PONTOS,':',5,64)\n",
            "LexToken(ID,'y',5,65)\n",
            "LexToken(FECHA_PAR,')',5,66)\n",
            "LexToken(INTEIRO,'inteiro',6,70)\n",
            "LexToken(DOIS_PONTOS,':',6,77)\n",
            "LexToken(ID,'res',6,79)\n",
            "LexToken(SE,'se',7,85)\n",
            "LexToken(ABRE_PAR,'(',7,88)\n",
            "LexToken(ID,'x',7,89)\n",
            "LexToken(MAIOR,'>',7,91)\n",
            "LexToken(ID,'y',7,93)\n",
            "LexToken(FECHA_PAR,')',7,94)\n",
            "LexToken(ENTAO,'então',7,96)\n",
            "LexToken(ID,'res',8,106)\n",
            "LexToken(ATRIBUICAO,':=',8,110)\n",
            "LexToken(ID,'x',8,113)\n",
            "LexToken(ADICAO,'+',8,115)\n",
            "LexToken(ID,'y',8,117)\n",
            "LexToken(SENAO,'senão',9,121)\n",
            "LexToken(ID,'res',10,131)\n",
            "LexToken(ATRIBUICAO,':=',10,135)\n",
            "LexToken(ID,'x',10,138)\n",
            "LexToken(MULTIPLICACAO,'*',10,140)\n",
            "LexToken(ID,'y',10,142)\n",
            "LexToken(FIM,'fim',11,146)\n",
            "LexToken(RETORNA,'retorna',12,152)\n",
            "LexToken(ABRE_PAR,'(',12,159)\n",
            "LexToken(ID,'res',12,160)\n",
            "LexToken(FECHA_PAR,')',12,163)\n",
            "LexToken(FIM,'fim',13,165)\n",
            "LexToken(ID,'func2',15,170)\n",
            "LexToken(ABRE_PAR,'(',15,175)\n",
            "LexToken(INTEIRO,'inteiro',15,176)\n",
            "LexToken(DOIS_PONTOS,':',15,183)\n",
            "LexToken(ID,'z',15,184)\n",
            "LexToken(VIRGULA,',',15,185)\n",
            "LexToken(FLUTUANTE,'flutuante',15,187)\n",
            "LexToken(DOIS_PONTOS,':',15,196)\n",
            "LexToken(ID,'w',15,197)\n",
            "LexToken(FECHA_PAR,')',15,198)\n",
            "LexToken(ID,'a',16,202)\n",
            "LexToken(ATRIBUICAO,':=',16,204)\n",
            "LexToken(ID,'z',16,207)\n",
            "LexToken(ID,'b',17,211)\n",
            "LexToken(ATRIBUICAO,':=',17,213)\n",
            "LexToken(ID,'w',17,216)\n",
            "LexToken(FIM,'fim',18,218)\n",
            "LexToken(INTEIRO,'inteiro',20,223)\n",
            "LexToken(ID,'principal',20,231)\n",
            "LexToken(ABRE_PAR,'(',20,240)\n",
            "LexToken(FECHA_PAR,')',20,241)\n",
            "LexToken(INTEIRO,'inteiro',21,245)\n",
            "LexToken(DOIS_PONTOS,':',21,252)\n",
            "LexToken(ID,'x',21,254)\n",
            "LexToken(VIRGULA,',',21,255)\n",
            "LexToken(ID,'y',21,256)\n",
            "LexToken(FLUTUANTE,'flutuante',22,260)\n",
            "LexToken(DOIS_PONTOS,':',22,269)\n",
            "LexToken(ID,'w',22,271)\n",
            "LexToken(ID,'a',23,275)\n",
            "LexToken(ATRIBUICAO,':=',23,277)\n",
            "LexToken(NUM_INTEIRO,'10',23,280)\n",
            "LexToken(ADICAO,'+',23,283)\n",
            "LexToken(NUM_INTEIRO,'2',23,285)\n",
            "LexToken(LEIA,'leia',24,289)\n",
            "LexToken(ABRE_PAR,'(',24,293)\n",
            "LexToken(ID,'x',24,294)\n",
            "LexToken(FECHA_PAR,')',24,295)\n",
            "LexToken(LEIA,'leia',25,299)\n",
            "LexToken(ABRE_PAR,'(',25,303)\n",
            "LexToken(ID,'w',25,304)\n",
            "LexToken(FECHA_PAR,')',25,305)\n",
            "LexToken(ID,'w',26,309)\n",
            "LexToken(ATRIBUICAO,':=',26,311)\n",
            "LexToken(NUM_PONTO_FLUTUANTE,'.6',26,314)\n",
            "LexToken(ADICAO,'+',26,317)\n",
            "LexToken(NUM_PONTO_FLUTUANTE,'1.',26,319)\n",
            "LexToken(ID,'func2',27,324)\n",
            "LexToken(ABRE_PAR,'(',27,329)\n",
            "LexToken(NUM_INTEIRO,'1',27,330)\n",
            "LexToken(VIRGULA,',',27,331)\n",
            "LexToken(NUM_PONTO_FLUTUANTE,'2.5',27,333)\n",
            "LexToken(FECHA_PAR,')',27,336)\n",
            "LexToken(ID,'b',28,340)\n",
            "LexToken(ATRIBUICAO,':=',28,342)\n",
            "LexToken(ID,'func1',28,345)\n",
            "LexToken(ABRE_PAR,'(',28,350)\n",
            "LexToken(ID,'x',28,351)\n",
            "LexToken(VIRGULA,',',28,352)\n",
            "LexToken(ID,'w',28,353)\n",
            "LexToken(FECHA_PAR,')',28,354)\n",
            "LexToken(ESCREVA,'escreva',29,358)\n",
            "LexToken(ABRE_PAR,'(',29,365)\n",
            "LexToken(ID,'b',29,366)\n",
            "LexToken(FECHA_PAR,')',29,367)\n",
            "LexToken(RETORNA,'retorna',30,371)\n",
            "LexToken(ABRE_PAR,'(',30,378)\n",
            "LexToken(NUM_INTEIRO,'0',30,379)\n",
            "LexToken(FECHA_PAR,')',30,380)\n",
            "LexToken(FIM,'fim',31,382)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TO_H9ZMxoG3M",
        "outputId": "040e1d0f-0dc6-4fa7-9745-be24b37807d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%%writefile teste.tpp\n",
        "\n",
        "inteiro: a[10]\n",
        "flutuante: b\n",
        "\n",
        "inteiro func1(inteiro:x, flutuante:y)\n",
        "  inteiro: res\n",
        "  se (x > y) então\n",
        "    res := x + y\n",
        "  senão\n",
        "    res := x * y\n",
        "  fim\n",
        "  retorna(res)\n",
        "fim\n",
        "\n",
        "func2(inteiro:z, flutuante:w)\n",
        "  a := z\n",
        "  b := w\n",
        "fim\n",
        "\n",
        "inteiro principal()\n",
        "  inteiro: x,y\n",
        "  flutuante: w\n",
        "  a := 10 + 2\n",
        "  leia(x)\n",
        "  leia(w)\n",
        "  w := .6 + 1.\n",
        "  func2(1, 2.5)\n",
        "  b := func1(x,w)\n",
        "  escreva(b)\n",
        "  retorna(0)\n",
        "fim\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting teste.tpp\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9UN81N7XBz_",
        "outputId": "4c80fe5c-2ed1-407d-eb63-078cdf42b3fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!python tpplex.py teste.tpp"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "python3: can't open file 'tpplex.py': [Errno 2] No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}